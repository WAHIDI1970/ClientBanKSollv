# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yis2FgZRzgOIa1BTB-V124jnob49K7om

#üìå**Sommaire du Notebook : Analyse Pr√©dictive de Solvabilit√© Bancaire :**
# * Chargement et visualisation des donn√©es.

# * Pr√©traitement des donn√©es.

# * Analyse exploratoire (EDA).

# * Mod√©lisation (R√©gression Logistique, KNN).

# * √âvaluation des performances des mod√®les avec k-fold Cross Validation .
"""

# Installer pyreadstat si besoin
!pip install pyreadstat

"""# üìä Pr√©paration des Donn√©es:"""

import pyreadstat
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve ,accuracy_score, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (confusion_matrix, classification_report,
                           accuracy_score, precision_score, recall_score,
                           f1_score, roc_auc_score, roc_curve, auc,
                           PrecisionRecallDisplay, precision_recall_curve)
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import numpy as np
from google.colab import files
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve
from imblearn.pipeline import Pipeline  # Notez l'utilisation de imblearn.pipeline
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from google.colab import files
uploaded = files.upload()

# Charger le fichier .sav
df,meta = pyreadstat.read_sav("/content/scoring.sav")

# Aper√ßu des donn√©es
df.head()

df.describe()

"""#üí† Analyse des Donn√©es :




"""

# Valeurs manquantes
print(df.isnull().sum())

# Distribution des variables num√©riques
df.hist(figsize=(12, 8), bins=20)
plt.suptitle("Histogrammes des variables", fontsize=16)
plt.tight_layout()
plt.show()

# Boxplots
for col in df.select_dtypes(include='number').columns:
    plt.figure()
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot de {col}")
    plt.show()

"""üëâ   *  les variables Amounte ,Expenses,Price et Income
pr√©sentent des outliers .
- Les outliers peuvent introduire un biais dans les analyses et les pr√©dictions, en particulier pour les mod√®les sensibles aux valeurs extr√™mes (comme la r√©gression).
- Une gestion efficace des outliers est n√©cessaire pour am√©liorer la robustesse des mod√®les.
"""

# Corr√©lation
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("Matrice de corr√©lation")
plt.show()

"""üëâ
- La forte corr√©lation entre `Amount` et `Price` peut poser des probl√®mes de multicolin√©arit√© de 0,73.
- La multicolin√©arit√© peut rendre les coefficients instables et nuire √† l'interpr√©tation des mod√®les, et pour ca on va suprimmer la variable Price par la suite .
"""

df['Amount'].describe()

df['Statut1'].describe()
nsolva = df[df.Statut1 == 1]
solva = df[df.Statut1 == 0]

nsolva.Amount.describe()

solva.Amount.describe()

"""üëâ   il y a un d√©s√©quilibre de classes dans la variable cible Statut1 :

- 742 cas pour Statut1 = 0
- 273 cas pour Statut1 = 1

---

# ‚úÖ la regression Logistique :

- Entra√Ænement d‚Äôun mod√®le de r√©gression logistique simple avec une base pr√©trait√©e Sans valeurs aberrantes (outliers supprim√©s) et √âquilibr√©e avec la m√©thode SMOTE pour corriger le d√©s√©quilibre des classes.

- Application de la validation crois√©e K-Fold pour :

- √âvaluer la robustesse du mod√®le.

- Identifier les meilleurs hyperparam√®tres.
"""

# S√©paration X / y
X = df.drop(columns='Statut1')
y = df['Statut1']

# D√©coupage train / test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardisation
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# √âquilibrage des classes avec SMOTE :"""

sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X_train_scaled, y_train)

# Mod√®le
log_model = LogisticRegression(class_weight='balanced', random_state=42)
log_model.fit(X_resampled, y_resampled)

# Pr√©dictions
y_pred_log = log_model.predict(X_test_scaled)

# 1. Calcul de la matrice de confusion
cm = confusion_matrix(y_test, y_pred_log)

# 2. Affichage avec seaborn (graphique am√©lior√©)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Non D√©faillant (0)", "D√©faillant (1)"],
            yticklabels=["Non D√©faillant (0)", "D√©faillant (1)"])
plt.title("Matrice de Confusion")
plt.xlabel("Pr√©dictions")
plt.ylabel("Vraies valeurs")
plt.show()

# √âvaluation
print(confusion_matrix(y_test, y_pred_log))
print(classification_report(y_test, y_pred_log))
print("AUC :", roc_auc_score(y_test, log_model.predict_proba(X_test_scaled)[:, 1]))

# ROC
fpr, tpr, _ = roc_curve(y_test, log_model.predict_proba(X_test_scaled)[:, 1])
plt.plot(fpr, tpr)
plt.xlabel("Faux positifs")
plt.ylabel("Vrais positifs")
plt.title("Courbe ROC - R√©gression Logistique")
plt.grid()
plt.show()

print("Nombre total :", len(y_test))
print("Classe 0 dans test :", sum(y_test == 0))
print("Classe 1 dans test :", sum(y_test == 1))

print("Nombre total :", len( y_resampled))
print("Classe 0 dans train :", sum(y_resampled == 0))
print("Classe 1 dans train :", sum(y_resampled == 1))

print("Nombre total :", len(y_train))
print("Classe 0 dans test :", sum(y_train == 0))
print("Classe 1 dans test :", sum(y_train == 1))

"""#  # ‚úÖ **la regression Logistique** sans ‚ùåoutliers(model final de regression logistique avec Recall=0,78 pour les cas NON solvables :"""

def detect_outliers_iqr(data, variable):
    Q1 = data[variable].quantile(0.25)
    Q3 = data[variable].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return ((data[variable] < lower_bound) | (data[variable] > upper_bound))

# Exemple : d√©tection des outliers pour Amount
df['outlier_amount'] = detect_outliers_iqr(df, 'Amount')

# Comptage des outliers par classe
df.groupby('Statut1')['outlier_amount'].sum()

# Liste des variables √† tester
variables = ['Amount', 'Expenses', 'Price', 'Income']

# Boucle pour cr√©er une colonne d'outliers pour chaque variable
for var in variables:
    df[f'outlier_{var.lower()}'] = detect_outliers_iqr(df, var)

# Regrouper par Statut1 et compter les outliers
outlier_counts = df.groupby('Statut1')[[f'outlier_{v.lower()}' for v in variables]].sum()

# Afficher les r√©sultats
print(outlier_counts)

df_clean = df[
    ~(df['outlier_amount'] | df['outlier_expenses'] | df['outlier_price'] | df['outlier_income'])
]

# S√©paration X / y
Xc = df_clean.drop(columns='Statut1')
yc =df_clean['Statut1']

# D√©coupage train / test
Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.2, random_state=42)

# Standardisation
scaler = StandardScaler()
Xc_train_scaled = scaler.fit_transform(Xc_train)
Xc_test_scaled = scaler.transform(Xc_test)

from imblearn.over_sampling import SMOTE

sm = SMOTE(random_state=42)
Xc_resampled, yc_resampled = sm.fit_resample(Xc_train_scaled, yc_train)

"""# üëâverification des outliers :"""

df_clean.describe()
# Boxplots
for col in df_clean.select_dtypes(include='number').columns:
    plt.figure()
    sns.boxplot(x=df_clean[col])
    plt.title(f"Boxplot de {col}")
    plt.show()

# Mod√®le
log_modelc= LogisticRegression(class_weight='balanced', random_state=42)
log_modelc.fit(Xc_resampled, yc_resampled)

# Pr√©dictions
yc_pred_log = log_modelc.predict(Xc_test_scaled)

# 4Ô∏è‚É£ √âvaluation
print("üìä Rapport de classification :\n", classification_report(yc_test, yc_pred_log))
# Attention : pour roc_auc_score, on pr√©f√®re les probabilit√©s pour la classe 1print("üìå AUC ROC :", roc_auc_score(yc_test, y_pred_proba))

# 5Ô∏è‚É£ Matrice de confusion
cm = confusion_matrix(yc_test, yc_pred_log)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Solvable (0)", "Non Solvable (1)"])
disp.plot(cmap='Blues')
plt.title("Matrice de confusion - Mod√®le final")
plt.grid(False)
plt.show()

"""#‚úÖ utilisation de la validation crois√©e k-fold pour √©valuer les performances des mod√®le de r√©gression logistique :





"""

# 3. Pipeline avec standardisation
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', LogisticRegression(random_state=42, class_weight='balanced'))  # Ajout du poids √©quilibr√©
])

# 4. Grille d'hyperparam√®tres optimis√©e
param_grid = {
    'model__C': np.logspace(-3, 2, 6),  # [0.001, 0.01, ..., 100]
    'model__penalty': ['l1', 'l2'],
    'model__solver': ['liblinear'],
    'model__max_iter': [500]
}

# 5. Recherche du meilleur mod√®le
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    scoring='f1',
    cv=5,
    n_jobs=-1,
    verbose=2
)

print("Optimisation en cours...")
grid_search.fit(Xc_train_scaled, yc_train)

# 6. Meilleur mod√®le
best_model = grid_search.best_estimator_
print("\nüîç Meilleurs param√®tres:", grid_search.best_params_)
print("üèÜ Meilleur score F1 (validation):", grid_search.best_score_)

y_proba = best_model.predict_proba(Xc_test_scaled)[:, 1]  # Probabilit√©s classe positive
precisions, recalls, thresholds = precision_recall_curve(yc_test, y_proba)

# Calcul du F1-score pour chaque seuil
f1_scores = (2 * precisions * recalls) / (precisions + recalls + 1e-8)
optimal_idx = np.argmax(f1_scores)
optimal_threshold = thresholds[optimal_idx]
print(f"\nüéØ Seuil optimal (max F1): {optimal_threshold:.4f}")

# 6. √âvaluation avec seuil optimis√©
y_pred_optimized = (y_proba >= optimal_threshold).astype(int)

print("\nüìä Rapport de classification optimis√©:")
print(classification_report(yc_test, y_pred_optimized,
                          target_names=['Solvable', 'Non solvable']))

# 7. Visualisation
plt.figure(figsize=(15, 5))

# Matrice de confusion
plt.subplot(1, 2, 1)
cm = confusion_matrix(yc_test, y_pred_optimized)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Solvable', 'Non solvable'],
            yticklabels=['Solvable', 'Non solvable'])
plt.title('Matrice de Confusion (seuil optimis√©)')

# Courbe Precision-Recall
plt.subplot(1, 2, 2)
PrecisionRecallDisplay.from_estimator(best_model, Xc_test_scaled, yc_test)
plt.title('Courbe Precision-Recall')
plt.tight_layout()
plt.show()

"""# ‚úÖle t√©l√©chargement du le meilleur mod√®le de r√©gression logistique :"""

# Correction du bloc de sauvegarde du mod√®le
model_data = {
    'model': best_model,
    'threshold': optimal_threshold,
    'features': list(range(X_resampled.shape[1])) if not hasattr(X_resampled, 'columns') else X_resampled.columns.tolist()
}
joblib.dump(model_data, 'REGLOG.pkl')
print("\nüíæ Mod√®le sauvegard√© sous 'REGLOG.pkl'")

"""# üîπKNN::

"""

class ModeleKNN:
    def __init__(self, k=5, weights='uniform'):
        """Initialise le mod√®le KNN

        Args:
            k (int): Nombre de voisins (d√©faut: 5)
            weights (str): 'uniform' ou 'distance' (d√©faut: 'uniform')
        """
        self.model = KNeighborsClassifier(n_neighbors=k, weights=weights)

    def entrainer(self, X_train, y_train):
        """Entra√Æne le mod√®le sur les donn√©es fournies"""
        self.model.fit(X_train, y_train)
        print(f"Mod√®le KNN entra√Æn√© avec {self.model.n_neighbors} voisins")

    def evaluer(self, X_test, y_test):
        """√âvalue le mod√®le et affiche les m√©triques"""
        # Pr√©dictions
        y_pred = self.model.predict(X_test)
        y_proba = self.model.predict_proba(X_test)[:, 1]

        # M√©triques
        print("\n" + "="*50)
        print("Rapport de classification :")
        print(classification_report(y_test, y_pred))

        print("\nMatrice de confusion :")
        plt.figure(figsize=(6, 4))
        sns.heatmap(confusion_matrix(y_test, y_pred),
                    annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Solvable', 'Non solvable'],
                    yticklabels=['Solvable', 'Non solvable'])
        plt.title('Matrice de Confusion')
        plt.show()

        # Courbe ROC
        fpr, tpr, _ = roc_curve(y_test, y_proba)
        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(y_test, y_proba):.2f}')
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlabel('Taux de faux positifs')
        plt.ylabel('Taux de vrais positifs')
        plt.title('Courbe ROC')
        plt.legend()
        plt.show()

        print("\n" + "="*50)

# Exemple d'utilisation avec vos donn√©es pr√©trait√©es :
if __name__ == "__main__":
    # Supposons que vous avez d√©j√† :
    # X_train, X_test, y_train, y_test = ... (donn√©es pr√©trait√©es)

    # 1. Initialisation
    knn = ModeleKNN(k=7, weights='distance')  # Testez avec diff√©rents k

    # 2. Entra√Ænement
    knn.entrainer(X_train,y_train)

    # 3. √âvaluation
    knn.evaluer(X_test, y_test)

"""##‚úÖ  Evaluation de KNN avec K-fold Cross Validation :
#choix du meilleur model :
"""

class ModeleKNNOptimise:
    def __init__(self):
        """Initialisation avec pipeline complet"""
        self.pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('smote', SMOTE(random_state=42)),
            ('knn', KNeighborsClassifier(weights='distance'))
        ])
        self.best_threshold = None

    def entrainer(self, X_train, y_train):
        """Entra√Ænement avec optimisation du seuil"""
        self.pipeline.fit(X_train, y_train)

        # Optimisation du seuil de d√©cision
        y_proba = self.pipeline.predict_proba(X_train)[:, 1]
        precisions, recalls, thresholds = precision_recall_curve(y_train, y_proba)
        f1_scores = (2 * precisions * recalls) / (precisions + recalls + 1e-8)
        self.best_threshold = thresholds[np.argmax(f1_scores)]

        print(f"Seuil optimal trouv√© : {self.best_threshold:.2f}")

    def evaluer(self, X_test, y_test):
        """√âvaluation avec seuil personnalis√©"""
        y_proba = self.pipeline.predict_proba(X_test)[:, 1]
        y_pred = (y_proba >= self.best_threshold).astype(int)

        print("\nRapport de classification optimis√©:")
        print(classification_report(y_test, y_pred,
                                 target_names=['Solvable', 'Non solvable']))

        # Visualisation
        plt.figure(figsize=(8, 4))
        sns.heatmap(confusion_matrix(y_test, y_pred),
                    annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Solvable', 'Non solvable'],
                    yticklabels=['Solvable', 'Non solvable'])
        plt.title(f"Matrice de Confusion (seuil={self.best_threshold:.2f})")
        plt.show()

# -------------------------------------------------------------------
# UTILISATION CORRECTE (partie importante)
# -------------------------------------------------------------------
if __name__ == "__main__":
    # 1. Initialisation
    knn_model = ModeleKNNOptimise()  # Cr√©e une instance sans 'self'

    # 2. Entra√Ænement (donn√©es doivent √™tre d√©finies)
    # Remplacez par vos vraies donn√©es:
    # knn_model.entrainer(X_train, y_train)

    # Exemple avec des donn√©es fictives (√† adapter):
    from sklearn.datasets import make_classification
    X, y = make_classification(n_samples=1000, weights=[0.9, 0.1], random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)

    knn_model.entrainer(X_train, y_train)  # Sans 'self'

    # 3. √âvaluation
    knn_model.evaluer(X_test, y_test)

"""# ‚úÖ le meilleur mod√®le KNN apr√®s la s√©lection :"""

joblib.dump(knn_model, 'KNN.pkl')
print("\nüíæ Mod√®le sauvegard√© sous 'KNN.pkl.pkl'")

files.download('REGLOG.pkl')
files.download('KNN.pkl')